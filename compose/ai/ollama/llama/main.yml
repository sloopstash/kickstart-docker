version: '3.8'
services:
  ollama-llama3.2_3b:
    image: sloopstash/ollama:v${AI_OLLAMA_VERSION}
    entrypoint: /usr/bin/supervisord
    command: "-c /etc/supervisord.conf"
    volumes:
      - sloopstash-ollama-llama3.2_3b-data:/root/.ollama
      - sloopstash-ollama-llama3.2_3b-log:/opt/ollama/log
      - ${HOME_DIR}/workload/supervisor/conf/server.conf:/etc/supervisord.conf
      - ${HOME_DIR}/workload/ollama/${AI_OLLAMA_VERSION}/conf/supervisor.ini:/opt/ollama/system/supervisor.ini
    networks:
      - common
    ports :
      - ${AI_OLLAMA_LLAMA_PORT}:11434
    environment:
      - OLLAMA_HOST=0.0.0.0
  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    volumes:
      - open-webui:/app/backend/data
    depends_on:
      - ollama-llama3.2_3b
    ports:
      - ${AI_OPEN_WEB_UI_LLAMA_PORT}:8080
    environment:
      - "OLLAMA_BASE_URLS=http://ollama-llama3.2_3b:11434"
      - WEBUI_SECRET_KEY=
      - DEFAULT_MODELS=llama3.2:3b
    extra_hosts:
      - host.docker.internal:host-gateway
    networks:
      - common
volumes:
  sloopstash-ollama-llama3.2_3b-data:
    driver: local
  sloopstash-ollama-llama3.2_3b-log:
    driver: local
  open-webui:
    driver: local
networks:
  common:
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: ${AI_OLLAMA_LLAMA_NETWORK}
